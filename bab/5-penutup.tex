\chapter{PENUTUP}
\label{chap:penutup}

% Ubah bagian-bagian berikut dengan isi dari penutup

\section{Kesimpulan}
\label{sec:kesimpulan}

Dalam penelitian telah diimplementasikan beberapa algoritma SOTA DRL dalam \emph{environment}
yang mengikuti mekanisme \emph{combat} dalam Civ6.
Dalam \emph{environment} ini, terdapat dua agen: agen \emph{attacker} dan agen \emph{defender}.
Kedua agen mempunyai tujuan yang berbeda \emph{asymmetrical} dan saling berlawanan \emph{adversarial}.
Dari eksperimen yang dilakukan dengan algoritma-algoritma tersebut, didapatkan:

\begin{enumerate}[nolistsep]

  \item DRL dapat menghasilkan agen yang optimal dalam \emph{environment} yang mensimulasi mekanisme \emph{combat}
  Civ6.

  \item APE-X DQN merupakan algoritma yang paling mumpuni. Agen \emph{attacker} dengan APE-X DQN mampu
  menghancurkan kota secara konsisten sebelum 2 juta \emph{environment steps}.
  Agen \emph{defender} dengan APE-X DQN juga merupakan salah satu algoritma yang paling optimal
  dibanding algoritma lain.

  \item APE-X DQN menggunakan RAM dan CPU terbanyak dengan penggunaan CPU sebanyak 79.95\% dan penggunaan
  RAM sebanyak 82.3\%.

\end{enumerate}

\section{Saran}
\label{chap:saran}

Dalam penelitian ini, ada beberapa aspek yang dapat diperbaiki untuk kedepannya:

\begin{enumerate}[nolistsep]

  \item Menambahkan tipe \emph{unit} yang lebih banyak dalam \emph{environment}: \emph{siege}, \emph{range}
  dengan jarak lebih jauh, \emph{cavalry}, dan \emph{recon}.

  \item Mengimplementasikan \emph{randomly generated terrain} pada \emph{environment} sehingga agen lebih
  mampu beradaptasi.

  \item Mengimplementasikan pemilihan \emph{unit} untuk agen yang lebih fleksibel dari pemilihan sekuensial
  yang digunakan sekarang, seperti menggunakan \emph{pointer net}.

  \item Melakukan hyperparameter tuning pada algoritma yang diuji coba.
  
  \item Mengintegrasikan algoritma ke dalam game engine seperti Unity3D.

\end{enumerate}
