Untuk setiap referensi, baris pertama (newton1687) merupakan label dan baris-baris berikutnya
merupakan atribut dari referensi yang akan digunakan. Umumnya, format referensi berikut sudah
disediakan oleh penyedia sumber referensi secara online dan bisa langsung ditaruh di sini.

Lihat https://www.bibtex.com/g/bibtex-format/ untuk informasi lebih lanjut mengenai format
BibTex yang digunakan pada file ini.


@article{chickParabola,
  author          = {Johnson, Soren},
  journal         = {Game Developer Magazine},
  title           = {Analysis: AI Fallibility And The Chick Parabola},
  volume          = {September},
  year            = {2010}
}

@article{humanLevelAI,
  author          = {John, Laird and Michael VanLent},
  journal         = {AI Magazine},
  title           = {Human-Level AI's Killer Application: Interactive Computer Games},
  volume          = {Vol. 22 No. 2: Summer 2001},
  year            = {2001}
}

@article{DRLSurvey,
  author          = {Kai, Arulkumaran and Marc, Peter, Deisenroth and Miles, Brundage and Anil, Anthony, Bharath},
  journal         = {IEEE Signal Processing Magazine},
  title           = {Deep Reinforcement Learning: A Brief Survey},
  volume          = {Vol. 34, no. 6},
  year            = {2017}
}

@article{civ6City,
  author          = {Athaillah, Ibnu  and Nugroho, Supeno Mardi Susiki and Hariadi, Mochamad},
  journal         = {IEEE},
  title           = {NSGA-II for City Building Placement Optimization in the Turn-based Game Civilization VI},
  volume          = {978-1-7281-2133},
  year            = {2019}
}

@article{civ4City,
  author          = {Wender, Stefan and Watson, Ian},
  journal         = {IEEE},
  title           = {Using Reinforcement Learning for City Site Selection in the Turn-Based Strategy Game Civilization IV},
  volume          = {978-1-4244-2974},
  year            = {2008}
}

@article{civ4RL,
  author          = {Amato. Christopher and Shani, Guy},
  journal         = {AAMAS},
  title           = {High-level Reinforcement Learning in Strategy Games},
  year            = {2010},
  volume          = {1},
}

@article{deepCrawl,
  author          = {Sestini, Alessandro and Kuhnle, Alexander and Bagdanov, Andrew, D.},
  journal         = {arXiv},
  title           = {DeepCrawl: Deep Reinforcement Learning for Turn-based Strategy Games},
  volume          = {2012.01914v1 [cs.LG]},
  year            = {2020}
}

@misc{civ6Combat,
  howpublished = {\url{https://civilization.fandom.com/wiki/Combat_(Civ6)}},
  title        = {Combat (Civ6)},
  note         = {Diakses pada: 21-03-2022}
}

@article{machineL,
author = {Simon and Annina and Deo and Mahima and Selvam and Venkatesan and Babu and Ramesh},
year = {2016},
month = {01},
pages = {22-24},
title = {An Overview of Machine Learning and its Applications},
journal = {International Journal of Electrical Sciences \& Engineering}
}

@BOOK{deepL,
  TITLE = {Deep Learning},
  AUTHOR = {Goodfellow, Ian},
  YEAR = {2015},
  PUBLISHER = {Cambridge: The MIT Press},
}

@BOOK{reinforcmentL,
  TITLE = {Reinforcement Learning An Introduction Second Edition},
  AUTHOR = {Richard, S, Sutton and Andrew, G, Barto},
  YEAR = {2018},
  PUBLISHER = {Cambridge: The MIT Press},
}

@article{deepRL,
  author          = {Li, Yuxi},
  journal         = {arXiv},
  pages          = {12},
  title           = {Deep Reinforcement Learning},
  volume          = {1810.06339v1},
  year            = {2018}
}

@article{deepQN,
  author          = {Mnih, V. and et al},
  journal         = {Nature},
  pages           = {529-533},
  title           = {Human-level control through deep reinforcement learning},
  volume          = {518(7540)},
  year            = {2015}
}

@article{deepQNFunction,
  author          = {Yuxi, Li},
  journal         = {arXiv},
  pages          = {24},
  title           = {Deep Reinforcement Learning},
  volume          = {1810.06339v1},
  year            = {2018}
}

@article{doubleQLearning,
  author          = {Hasselt, Hado van},
  journal         = {Advances in neural information processing systems 23},
  title           = {Double Q-learning},
  year            = {2010}
}

@article{doubleDQN,
  author          = {Hasselt, Hado van and Guez, Arthur  and Silver, David},
  journal         = {arXiv},
  title           = {Deep Reinforcement Learning with Double Q-learning},
  volume          = {1509.06461},
  year            = {2015}
}

@article{prioritizedER,
  author          = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal         = {arXiv},
  title           = {Prioritized Experience Replay},
  volume          = {1511.05952},
  year            = {2015}
}

@article{duelingDQN,
  author          = {Ziyu, Wang and Schaul, Tom and Hessel, Matteo and Hasselt, Hado van and Lanctot, Marc and Freitas, Nando de},
  journal         = {arXiv},
  title           = {Dueling Network Architectures for Deep Reinforcement Learning},
  volume          = {1511.06581},
  year            = {2015}
}

@article{ppo,
  author          = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal         = {arXiv},
  title           = {Proximal Policy Optimization Algorithms},
  volume          = {1707.06347v2},
  year            = {2017}
}

@article{apexDQN,
  author          = {Horgan, Dan and Quan, John and Budden, David and Barth-Maron, Gabriel and Hessel, Mateo and Hasselt, Hado van and Silver, David},
  journal         = {arXiv},
  title           = {Distributed Prioritized Experience Replay},
  volume          = {1803.00933},
  year            = {2018}
}

@misc{civ6Environment,
  author = InquisitiveOtter,
  howpublished = {\url{https://github.com/InquisitiveOtter/ML_CIV6}},
  title        = {MLCIV6},
  note         = {Diakses pada: 21-03-2022}
}

@article{alphaStar,
  author          = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and et al},
  journal         = {Nature},
  title           = {Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  volume          = {575},
  year            = {2019}
}

@article{openaiDota2,
  author          = {Berner, Christopher and Brockman, Greg and Chan, Brooke and et al},
  journal         = {arXiv},
  volume          = {1912.06680},
  title           = {Dota 2 with large scale deep reinforcement learning},
  year            = {2019}
}

@article{pettingZoo,
  author          = {Terry, J and Black, Benjamin and Grammel, Nathaniel and et al},
  journal         = {Advances in Neural Information Processing Systems, 34},
  volume          = {15032-15043},
  title           = {Pettingzoo: Gym for multi-agent reinforcement learning},
  year            = {2021}
}

@article{impala,
  author          = {Espeholt and Lasse and Hubert, Soyer and Remi, Munos and Karen, Simonyan and Vlad, Mnih and Tom, Ward and Yotam, Doron and et al},
  journal         = {International conference on machine learning},
  pages           = {1407-1416},
  title           = {Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  year            = {2018}
}

@article{rllib,
  author          = {Eric, Liang and Richard, Liaw and Robert, Nishihara and Philipp, Moritz and Roy, Fox and Ken, Goldberg and Joseph, Gonzalez and Michael, Jordan and Ion, Stoica},
  journal         = {Proceedings of the 35th International Conference on Machine Learning},
  pages           = {80:3053-3062},
  title           = {RLlib: Abstractions for Distributed Reinforcement Learning},
  year            = {2018}
}

@misc{rllibDocumentation,
  howpublished = {\url{https://docs.ray.io/en/latest/rllib/index.html}},
  title        = {RLlib: Industry-Grade Reinforcement Learning - Ray 2.0.0.},
  note         = {Diakses pada: 19-10-2022}
}

@misc{civ6CopiesSold,
  howpublished = {\url{https://store.2k.com/en/civilization}},
  title        = {Civilization 6 Copies Sold},
  note         = {Diakses pada: 15-1-2023}
}